{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Python Optimization Using 'isin' and 'apply'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**[Stack Overflow Question: Python - For loop millons of rows](https://stackoverflow.com/questions/52279699/python-for-loop-millions-of-rows)**\n",
    "\n",
    "This solution uses pd.DataFrame.isin which uses [numpy.in1d](https://docs.scipy.org/doc/numpy/reference/generated/numpy.in1d.html)\n",
    "\n",
    "Apparently 'isin' isn't necessarily faster for small datasets (like this sample), but is significantly faster for large datasets. You'll have to run it against your data to determine performance.\n",
    "\n",
    "Expanded the dataset using c = pd.concat([c] * 10000, ignore_index=True)\n",
    "\n",
    "* Increase the dataset length by 3 orders of magnitude (10000 rows total).\n",
    " * Original method: Wall time: 8.98s\n",
    " * New method 2: Wall time: 16.4s\n",
    "* Increase the dataset length by 4 orders of magnitude (100000 rows total).\n",
    " * Original method: Wall time: 8min 17s\n",
    " * New method 2: Wall time: 1min 14s\n",
    "* Increase the dataset length by 5 orders of magnitude (1000000 rows total).\n",
    " * New method 2: Wall time: 11min 33s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import io\n",
    "from pprint import pprint as pp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = '''\n",
    " A_D     Operator     FlightID    Terminal   TROUND_ID   tot\n",
    " A   QR  QR001   4   QR002       70\n",
    " D   DL  DL001   3   \"        \"  84\n",
    " D   DL  DL001   3   \"        \"  78\n",
    " D   VS  VS001   3   \"        \"  45\n",
    " A   DL  DL401   3   \"        \"  9\n",
    " A   DL  DL401   3   \"        \"  19\n",
    " A   DL  DL401   3   \"        \"  3\n",
    " A   DL  DL401   3   \"        \"  32\n",
    " A   DL  DL401   3   \"        \"  95\n",
    " A   DL  DL402   3   \"        \"  58\n",
    "'''\n",
    "\n",
    "data_aux = pd.read_table(io.StringIO(s), delim_whitespace=True)\n",
    "data_aux.Terminal = data_aux.Terminal.astype(str)\n",
    "data_aux.tot= data_aux.tot.astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_aux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = {'START': ['2017-03-26 16:55:00', '2017-03-26 09:30:00','2017-03-27 09:30:00','2017-10-08 15:15:00',\n",
    "           '2017-03-26 06:50:00','2017-03-27 06:50:00','2017-03-29 06:50:00','2017-05-03 06:50:00',\n",
    "           '2017-06-25 06:50:00','2017-03-26 07:45:00'], 'END': ['2017-10-28 16:55:00' ,'2017-06-11 09:30:00' ,\n",
    "           '2017-10-28 09:30:00' ,'2017-10-22 15:15:00','2017-06-11 06:50:00' ,'2017-10-28 06:50:00', \n",
    "           '2017-04-19 06:50:00' ,'2017-10-25 06:50:00','2017-10-22 06:50:00' ,'2017-10-28 07:45:00']}    \n",
    "\n",
    "aux_df = pd.DataFrame(data=d)\n",
    "aux_df.START = pd.to_datetime(aux_df.START)\n",
    "aux_df.END = pd.to_datetime(aux_df.END)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "aux_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = pd.concat([aux_df, data_aux], axis = 1)\n",
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create the c & arr DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def config_df(aux_df, data_aux):\n",
    "    \"\"\"\n",
    "    creates c & arr DataFrame\n",
    "    \"\"\"\n",
    "    c = pd.concat([aux_df, data_aux], axis = 1)\n",
    "    c['A_D'] = c['A_D'].astype(str)\n",
    "    c['Operator'] = c['Operator'].astype(str)\n",
    "    c['Terminal'] = c['Terminal'].astype(str)\n",
    "\n",
    "    c['hour'] = c['START'].dt.time\n",
    "    c['hour_aux'] = (c['START'] - pd.Timedelta(15, unit='m')).dt.time\n",
    "    \n",
    "    c['start_day'] = c['START'].astype(str).str[0:10]\n",
    "    c['end_day'] = c['END'].astype(str).str[0:10]\n",
    "    c['x'] = c.START -  pd.to_timedelta(c.tot.astype(int), unit='m')\n",
    "    c[\"a\"] = 0\n",
    "    c[\"Already_linked\"] = np.where(c.TROUND_ID != \" \"*8, 1 ,0)\n",
    "    \n",
    "    c = pd.concat([c] * 100000, ignore_index=True)\n",
    "\n",
    "    arr = c[c['A_D'] == 'A'].copy()\n",
    "    return c, arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%time c, arr = config_df(aux_df=aux_df, data_aux=data_aux)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Produce Final Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def final_output(c, arr):\n",
    "    c['Already_linked'] = np.where((c.a != 0) & (c.a != 'No_link_found') & (c.A_D == 'D'), 1, c['Already_linked'])\n",
    "    c.Already_linked.loc[arr.Already_linked.index] = arr.Already_linked\n",
    "    c['a'] = np.where((c.Already_linked  == 0) & (c.A_D == 'D'),'No_link_found',c['a'])\n",
    "    return c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Original Code\n",
    "\n",
    "### Faster for sets at least to 10000 rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def original_way():\n",
    "    \"\"\"\n",
    "    updates c & arr\n",
    "    \"\"\"\n",
    "    groups = arr.groupby(['Operator', 'Terminal'])\n",
    "    for row in c[(c.A_D == \"D\") & (c.Already_linked == 0)].itertuples():\n",
    "        try:\n",
    "            g = groups.get_group((row.Operator, row.Terminal))\n",
    "            vb = g[(g.Already_linked==0) & (g.hour<row.hour_aux)]\n",
    "            aux = (vb.START - row.x).abs().idxmin()\n",
    "            c.loc[row.Index, 'a'] = vb.loc[aux].FlightID\n",
    "            arr.loc[aux, 'Already_linked'] = 1\n",
    "            continue\n",
    "        except:\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# refresh c and arr to original form\n",
    "c, arr = config_df(aux_df=aux_df, data_aux=data_aux)\n",
    "\n",
    "%time original_way()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Expected c & r from Original Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_expected = c\n",
    "c_expected.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr_expected = arr\n",
    "arr_expected.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Expected Final Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_output(c, arr)\n",
    "expected_final_c = c\n",
    "expected_final_c.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# New Method 1: Using isin and itertuples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def do_g(df_test):\n",
    "    \"\"\"\n",
    "    This is your function, but using isin and itertuples\n",
    "    \"\"\"\n",
    "    \n",
    "    for it_row in df_test.itertuples():\n",
    "        \n",
    "        keep = {'Operator': [it_row.Operator], 'Terminal': [it_row.Terminal]}  # dict for isin combined mask\n",
    "        \n",
    "        holder1 = arr[list(keep)].isin(keep).all(axis=1)  # create boolean mask\n",
    "        holder2 = arr.Already_linked.isin([0])  # create boolean mask\n",
    "        holder3 = arr.hour < it_row.hour_aux  # create boolean mask\n",
    "        \n",
    "        holder = holder1 & holder2 & holder3  # combine the masks\n",
    "        \n",
    "        holder = arr.loc[holder]\n",
    "\n",
    "        if not holder.empty:\n",
    "\n",
    "            aux = np.absolute(holder.START - it_row.x).idxmin()\n",
    "\n",
    "            c.loc[it_row.Index, 'a'] = holder.loc[aux].FlightID  # use with itertuples 'it_row.Index'\n",
    "\n",
    "            arr.loc[aux, 'Already_linked'] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### call the function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reset c and arr\n",
    "c, arr = config_df(aux_df=aux_df, data_aux=data_aux)\n",
    "\n",
    "# create the subset of the 'c' DataFrame\n",
    "keep = {'A_D': ['D'], 'Already_linked': [0]}\n",
    "df_test = c[c[list(keep)].isin(keep).all(axis=1)].copy()  # returns the resultant df\n",
    "\n",
    "# call the do_g function\n",
    "%time do_g(df_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# New Method 2: Using isin and apply\n",
    "\n",
    "### Fastest for sets greater than 100000 in this example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_do_g(it_row):\n",
    "    \"\"\"\n",
    "    This is your function, but using isin and apply\n",
    "    \"\"\"\n",
    "    \n",
    "    keep = {'Operator': [it_row.Operator], 'Terminal': [it_row.Terminal]}  # dict for isin combined mask\n",
    "\n",
    "    holder1 = arr[list(keep)].isin(keep).all(axis=1)  # create boolean mask\n",
    "    holder2 = arr.Already_linked.isin([0])  # create boolean mask\n",
    "    holder3 = arr.hour < it_row.hour_aux\n",
    "    \n",
    "    holder = holder1 & holder2 & holder3  # combine the masks\n",
    "\n",
    "    holder = arr.loc[holder]\n",
    "\n",
    "    if not holder.empty:\n",
    "\n",
    "        aux = np.absolute(holder.START - it_row.x).idxmin()\n",
    "\n",
    "        c.loc[it_row.name, 'a'] = holder.loc[aux].FlightID  # use with apply 'it_row.name'\n",
    "        \n",
    "        arr.loc[aux, 'Already_linked'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def new_way_2():\n",
    "    keep = {'A_D': ['D'], 'Already_linked': [0]}\n",
    "    %time df_test = c[c[list(keep)].isin(keep).all(axis=1)].copy()  # returns the resultant df\n",
    "    df_test.apply(lambda row: apply_do_g(row), axis=1)  # g is multiple DataFrames\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### call the function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reset c and arr\n",
    "c, arr = config_df(aux_df=aux_df, data_aux=data_aux)\n",
    "\n",
    "#call the function\n",
    "%time new_way_2()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# New Final Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_output(c, arr)\n",
    "new_final_c = c\n",
    "new_final_c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare new c & arr to expected c & arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr == arr_expected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c == c_expected"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare Original Final Output to New Final Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_final_c == expected_final_c"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
