{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimizing Using Pandas DataFrame\n",
    "\n",
    "### Solution for Stack Overflow question\n",
    "### 2018-09-13\n",
    "\n",
    "https://stackoverflow.com/questions/52305104/optimizing-using-pandas-data-frame/52310584#52310584"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "from haversine import haversine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main_function(df, row):\n",
    "    \"\"\"\n",
    "    The main difference here is that everything is vectorized\n",
    "    Returns: DataFrame\n",
    "    \"\"\"\n",
    "    \n",
    "    df_new = pd.DataFrame()\n",
    "    df_storage = pd.DataFrame()\n",
    "    \n",
    "    pos_datetime = df.POSDATETIME.isin([row['POSDATETIME']])  # creates a Boolean map\n",
    "    array_len = len(pos_datetime)\n",
    "    new_index = pos_datetime.index\n",
    "\n",
    "    df_new['StormID'] = df.loc[pos_datetime, 'STORMID']\n",
    "    df_new['ModelBaseTime'] = df.loc[pos_datetime, 'MODELDATETIME']\n",
    "    df_new['Model'] = df.loc[pos_datetime, 'MODEL']\n",
    "    df_new['Tau'] = df.loc[pos_datetime, 'TAU']\n",
    "    \n",
    "    # Distance\n",
    "    df_new['LatCARQ'] = pd.DataFrame(np.full((array_len, 1), row['LAT']), index=new_index).loc[pos_datetime, 0]\n",
    "    df_new['LonCARQ'] = pd.DataFrame(np.full((array_len, 1), row['LON']), index=new_index).loc[pos_datetime, 0]\n",
    "    df_new['LatModel'] = df.loc[pos_datetime, 'LAT']\n",
    "    df_new['LonModel'] = df.loc[pos_datetime, 'LON']\n",
    "\n",
    "    \n",
    "    def calc_dist_error(row):\n",
    "        return round(haversine((row['LatCARQ'], row['LonCARQ']), (row['LatModel'], row['LonModel']), miles=True)) if row['LatModel'] != 0.0 else None\n",
    "    \n",
    "    df_new['DistError'] = df_new.apply(calc_dist_error, axis=1)\n",
    "    \n",
    "    # Wind\n",
    "    df_new['WindCARQ'] = pd.DataFrame(np.full((array_len, 1), row['WIND']), index=new_index).loc[pos_datetime, 0]\n",
    "    df_new['WindModel'] = df.loc[pos_datetime, 'WIND']\n",
    "    df_storage['row_WIND'] = pd.DataFrame(np.full((array_len, 1), row['WIND']), index=new_index).loc[pos_datetime, 0]\n",
    "    df_storage['df_WIND'] = df.loc[pos_datetime, 'WIND']\n",
    "    \n",
    "    \n",
    "    def wind_error_calc(row):\n",
    "        return (row['row_WIND'] - row['df_WIND']) if row['df_WIND'] != 0 else None\n",
    "\n",
    "    df_new['WindError'] = df_storage.apply(wind_error_calc, axis=1)\n",
    "    \n",
    "    # Air Pressure\n",
    "    df_new['PresCARQ'] = pd.DataFrame(np.full((array_len, 1), row['PRES']), index=new_index).loc[pos_datetime, 0]\n",
    "    df_new['PresModel'] = df.loc[pos_datetime, 'PRES']\n",
    "    df_storage['row_PRES'] = pd.DataFrame(np.full((array_len, 1), row['PRES']), index=new_index).loc[pos_datetime, 0]\n",
    "    df_storage['df_PRES'] = df.loc[pos_datetime, 'PRES']\n",
    "\n",
    "    \n",
    "    def pres_error_calc(row):\n",
    "        return abs(row['row_PRES'] - row['df_PRES']) if row['df_PRES'] != 0 else None\n",
    "\n",
    "    df_new['PresError'] = df_storage.apply(pres_error_calc, axis=1)\n",
    "    \n",
    "    del(df_storage)\n",
    "\n",
    "    return df_new\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_adeck_errors(in_file):\n",
    "    \"\"\"\n",
    "    Retruns: DataFrame\n",
    "    \"\"\"\n",
    "    print(f'Starting Data Calculations: {datetime.datetime.now().strftime(\"%I:%M:%S%p on %B %d, %Y\")}')\n",
    "    pd.set_option('max_columns', 20)\n",
    "    pd.set_option('max_rows', 300)\n",
    "          \n",
    "    # read in the raw csv\n",
    "    adeck_df = pd.read_csv(in_file)\n",
    "    adeck_df['MODELDATETIME'] = pd.to_datetime(adeck_df['MODELDATETIME'], format='%Y-%m-%d %H:%M')\n",
    "    adeck_df['POSDATETIME'] = pd.to_datetime(adeck_df['POSDATETIME'], format='%Y-%m-%d %H:%M')\n",
    "    \n",
    "    #extract only the carq items and remove duplicates\n",
    "    carq_data = adeck_df[(adeck_df.MODEL == 'CARQ') & (adeck_df.TAU == 0)].drop_duplicates(keep='last')    \n",
    "    print('Len carq_data: ', len(carq_data))\n",
    "          \n",
    "    #remove carq items from original\n",
    "    final_df = adeck_df[adeck_df.MODEL != 'CARQ']\n",
    "    print('Len final_df: ', len(final_df))\n",
    "                  \n",
    "    df_out_new = pd.DataFrame()\n",
    "\n",
    "    for index, row in carq_data.iterrows():\n",
    "\n",
    "        test_df = main_function(final_df, row)  # function call\n",
    "\n",
    "        df_out_new = df_out_new.append(test_df, sort=False)\n",
    "        \n",
    "\n",
    "    df_out_new = df_out_new.reset_index(drop=True)\n",
    "    df_out_new = df_out_new.where((pd.notnull(df_out_new)), None)\n",
    "    \n",
    "    print(f'Finishing Data Calculations: {datetime.datetime.now().strftime(\"%I:%M:%S%p on %B %d, %Y\")}')\n",
    "    return df_out_new\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_file = 'data/aal062018.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = calculate_adeck_errors(in_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Original Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_adeck_errors(in_file):\n",
    "    print(f'Starting Data Calculations: {datetime.datetime.now().strftime(\"%I:%M%p on %B %d, %Y\")}')\n",
    "    pd.set_option('display.max_columns', 12)\n",
    "\n",
    "    # read in the raw csv\n",
    "    adeck_df = pd.read_csv(in_file)\n",
    "    #print(adeck_df)\n",
    "\n",
    "    #extract only the carq items and remove duplicates\n",
    "    carq_data = adeck_df[(adeck_df.MODEL == 'CARQ') & (adeck_df.TAU == 0)].drop_duplicates(keep='last')\n",
    "    #print(carq_data)\n",
    "\n",
    "    #remove carq items from original\n",
    "    final_df = adeck_df[adeck_df.MODEL != 'CARQ']\n",
    "    #print(final_df)\n",
    "\n",
    "    row_list = []\n",
    "    for index, row in carq_data.iterrows():\n",
    "        position_time = row['POSDATETIME']\n",
    "        for index, arow in final_df.iterrows():\n",
    "            if arow['POSDATETIME'] == position_time:\n",
    "                # match, so do calculations\n",
    "                storm_id = arow['STORMID']\n",
    "                model_base_time = arow['MODELDATETIME']\n",
    "                the_hour = arow['TAU']\n",
    "                the_model = arow['MODEL']\n",
    "                point1 = float(row['LAT']), float(row['LON'])\n",
    "                point2 = float(arow['LAT']), float(arow['LON'])\n",
    "                if arow['LAT'] == 0.0:\n",
    "                    dist_error = None\n",
    "                else:\n",
    "                    dist_error = int(round(haversine(point1, point2, miles=True)))\n",
    "\n",
    "                if arow['WIND'] != 0:\n",
    "                    wind_error = int(abs(int(row['WIND']) - int(arow['WIND'])))\n",
    "                else: wind_error = None\n",
    "\n",
    "                if arow['PRES'] != 0:\n",
    "                    pressure_error = int(abs(int(row['PRES']) - int(arow['PRES'])))\n",
    "                else:\n",
    "                    pressure_error = None\n",
    "\n",
    "                lat_carq = row['LAT']\n",
    "                lon_carq = row['LON']\n",
    "                lat_model = arow['LAT']\n",
    "                lon_model = arow['LON']\n",
    "                wind_carq = row['WIND']\n",
    "                wind_model = arow['WIND']\n",
    "                pres_carq = row['PRES']\n",
    "                pres_model = arow['PRES']\n",
    "\n",
    "                row_list.append([storm_id, model_base_time, the_model, the_hour, lat_carq, lon_carq, lat_model, lon_model, dist_error,\n",
    "                             wind_carq, wind_model, wind_error, pres_carq, pres_model, pressure_error])\n",
    "\n",
    "    result_df = pd.DataFrame(row_list)\n",
    "    result_df = result_df.where((pd.notnull(result_df)), None)\n",
    "    result_cols = ['StormID', 'ModelBasetime', 'Model' , 'Tau',\n",
    "               'LatCARQ', 'LonCARQ', 'LatModel', 'LonModel', 'DistError',\n",
    "               'WindCARQ', 'WindModel','WindError',\n",
    "               'PresCARQ', 'PresModel','PresError']\n",
    "\n",
    "    result_df.columns = result_cols\n",
    "          \n",
    "    return result_df\n",
    "\n",
    "in_file = 'data/aal062018.csv'\n",
    "df = calculate_adeck_errors(infile)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
