{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [AttributeError when building list comprehension for Wordnet.Synsets().Definition()](https://stackoverflow.com/questions/52392130/attributeerror-when-building-list-comprehension-for-wordnet-synsets-definition/52394042?noredirect=1#comment91733736_52394042)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pprint import pprint as pp\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.corpus import wordnet as wn\n",
    "\n",
    "# these two methods do the same thing\n",
    "from nltk.tokenize import TreebankWordTokenizer as tok\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/2018-09-18_CIP.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "english_stops = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gets synsets for a given term.\n",
    "\n",
    "def get_synset(word):\n",
    "    for word in wn.synsets(word):\n",
    "        return word.name()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Gets definitions for a synset.\n",
    "\n",
    "def get_def(syn):\n",
    "    return wn.synset(syn).definition()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates a dataframe called sector_matrix based on another dataframe's column. Should be followed with an export.\n",
    "\n",
    "def sector_tagger(frame):\n",
    "    \"\"\"\n",
    "    Receives each row of the DataFrame column - using apply\n",
    "    Transform the row using NLTK to produce a DataFrame series with Categories\n",
    "    of individual words, synsets, and word definitions.\n",
    "    :parameter: frame\n",
    "    :type: string\n",
    "    :return: sector_matrix, synset, def_matrix\n",
    "    :type: pandas.core.series.Series\n",
    "    \"\"\"\n",
    "    mapping = [('/', ' '), ('(', ''), (')', ''), (',', '')]\n",
    "    for k, v in mapping:\n",
    "        frame = frame.replace(k, v)\n",
    "        \n",
    "    # these two lines do the same thing with different methods\n",
    "#     tok_list = tok().tokenize(frame)\n",
    "    tok_list = word_tokenize(frame)\n",
    "\n",
    "    split_words = [w.lower() for w in tok_list]\n",
    "    clean_words = [w for w in split_words if w not in english_stops]\n",
    "    synset = [get_synset(w) for w in clean_words]\n",
    "    def_matrix = [get_def(w) if w != None else '' for w in synset]\n",
    "    return clean_words, synset, def_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agri_set = df['Category'].apply(sector_tagger)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### each phrase passed in returns a list clean_words, synsets and phrases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agri_set[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a DataFrame where each column is a list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_clean_words = []\n",
    "list_synset = []\n",
    "list_def_matrix = []\n",
    "for x in agri_set:\n",
    "    list_clean_words.append(x[0])\n",
    "    list_synset.append(x[1])\n",
    "    list_def_matrix.append(x[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agri_matrix = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agri_matrix['Categories'] = list_clean_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agri_matrix['Synsets'] = list_synset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agri_matrix['Definition'] = list_def_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agri_matrix.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Alternatively, split each list of lists into a long list (they're ordered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_long_list_from_list_of_lists(list_of_lists):\n",
    "    long_list = []\n",
    "    for one_list in list_of_lists:\n",
    "        for word in one_list:\n",
    "            long_list.append(word)\n",
    "    return long_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "long_list_clean_words = create_long_list_from_list_of_lists(list_clean_words)\n",
    "long_list_synset = create_long_list_from_list_of_lists(list_synset)\n",
    "long_list_def_matrix = create_long_list_from_list_of_lists(list_def_matrix)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Turn it into a DataFrame of Uniques Categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agri_df = pd.DataFrame.from_dict(dict([('Categories', long_list_clean_words), ('Synsets', long_list_synset), ('Definitions', long_list_def_matrix)])).drop_duplicates().reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agri_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Alternate sector_tagger Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates a dataframe called sector_matrix based on another dataframe's column. Should be followed with an export.\n",
    "\n",
    "def sector_tagger(frame):\n",
    "    \"\"\"\n",
    "    Receives one entire DataFrame column not a row, like with apply\n",
    "    Transform the column using NLTK to produce a DataFrame with Categories\n",
    "    of individual words, synsets, and word definitions.\n",
    "    :parameter: frame\n",
    "    :type: pandas.core.series.Series\n",
    "    :return: sector_matrix\n",
    "    :type: pandas.core.frame.DataFrame\n",
    "    \"\"\"\n",
    "\n",
    "    mapping = [('/', ' '), ('(', ''), (')', ''), (',', '')]\n",
    "    for k, v in mapping:\n",
    "        frame = frame.apply(lambda row: row.replace(k, v))\n",
    "        \n",
    "    # these two lines do the same thing with different methods\n",
    "#     tok_list = [tok().tokenize(w) for w in frame]\n",
    "    tok_list = [word_tokenize(w) for w in frame]\n",
    "\n",
    "    split_words = [w.lower() for sub in tok_list for w in sub]\n",
    "    clean_words = [w for w in split_words if w not in english_stops]\n",
    "    synset = [get_synset(w) for w in clean_words]\n",
    "    \n",
    "    sector_matrix = pd.DataFrame({'Categories': clean_words, 'Synsets': synset})\n",
    "    sec_syn = list(sector_matrix['Synsets'])\n",
    "    sector_matrix['Definition'] = [get_def(w) if w != None else '' for w in sec_syn]\n",
    "    sector_matrix = sector_matrix.drop_duplicates().reset_index(drop=True)\n",
    "    return sector_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agri_matrix = sector_tagger(df['Category'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agri_matrix.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Original Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pandas import DataFrame, Series\n",
    "import nltk.data\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.corpus import wordnet as wn\n",
    "from nltk.tokenize import TreebankWordTokenizer\n",
    "\n",
    "\n",
    "tok = TreebankWordTokenizer()\n",
    "english_stops = set(stopwords.words('english'))\n",
    "french_stops = set(stopwords.words('french'))\n",
    "\n",
    "\n",
    "# Gets synsets for a given term.\n",
    "\n",
    "def get_synset(word):\n",
    "    for word in wn.synsets(word):\n",
    "        return word.name()\n",
    "\n",
    "#Gets definitions for a synset.\n",
    "\n",
    "def get_def(syn):\n",
    "    return wn.synsets(syn).definition()\n",
    "\n",
    "# Creates a dataframe called sector_matrix based on another dataframe's column. Should be followed with an export.\n",
    "\n",
    "def sector_tagger(frame):\n",
    "    sentences = frame.tolist()\n",
    "    tok_list = [tok.tokenize(w) for w in frame]\n",
    "    split_words = [w.lower() for sub in tok_list for w in sub]\n",
    "    clean_words = [w for w in split_words if w not in english_stops]\n",
    "    synset = [get_synset(w) for w in clean_words]\n",
    "    sector_matrix = DataFrame({'Categories': clean_words,\n",
    "                               'Synsets': synset})\n",
    "    sec_syn = sector_matrix['Synsets'].tolist()\n",
    "    sector_matrix['Definition'] = [get_def(w) for w in sector_matrix['Synsets']]\n",
    "    return sector_matrix\n",
    "\n",
    "test = pd.read_csv('data/2018-09-18_CIP.csv')\n",
    "\n",
    "agri_matrix = sector_tagger(test['Category'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
